{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7193555c",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c48f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib as plt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14c7aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 855/855 [00:02<00:00, 349.93it/s]\n",
      "100%|████████████████████████████████████████| 855/855 [00:03<00:00, 267.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def sorted_alphanumeric(data):  \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() #lowercase\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)] \n",
    "    return sorted(data,key = alphanum_key)\n",
    "\n",
    "# defining the size of the image\n",
    "SIZE = 512\n",
    "high_img = []\n",
    "path = 'dataset/train/high_res/'\n",
    "path2 = 'dataset/val/high_res/'\n",
    "files = os.listdir(path)\n",
    "files.extend(os.listdir(path2))\n",
    "files = sorted_alphanumeric(files)\n",
    "for i in tqdm(files):    \n",
    "    if i == '855.jpg':\n",
    "        break\n",
    "    else:    \n",
    "        img = cv2.imread(path + '/'+i,1)\n",
    "        # open cv reads images in BGR format so we have to convert it to RGB\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #resizing image\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        high_img.append(img_to_array(img))\n",
    "\n",
    "\n",
    "low_img = []\n",
    "path = 'dataset/train/low_res/'\n",
    "path2 = 'dataset/val/low_res/'\n",
    "files = os.listdir(path)\n",
    "files.extend(os.listdir(path2))\n",
    "\n",
    "files = sorted_alphanumeric(files)\n",
    "for i in tqdm(files):\n",
    "     if i == '855.jpg':\n",
    "        break\n",
    "     else: \n",
    "        img = cv2.imread(path + '/'+i,1)\n",
    "\n",
    "        #resizing image\n",
    "     \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        low_img.append(img_to_array(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47809d76",
   "metadata": {},
   "source": [
    "# Plotting PSNR and SSIM Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33a7308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1)))) / 2.303\n",
    "\n",
    "def SSIM(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n",
    "def pixel_mse_loss(x,y):\n",
    "    return tf.reduce_mean( (x - y) ** 2 )\n",
    "\n",
    "def model_train_plot(history):\n",
    "    \n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    plt.plot(history.history['SSIM'])\n",
    "    plt.plot(history.history['val_SSIM'])\n",
    "    plt.title('model SSIM')\n",
    "    plt.ylabel('SSIM')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['PSNR'])\n",
    "    plt.plot(history.history['val_PSNR'])\n",
    "    plt.title('model PSNR')\n",
    "    plt.ylabel('PSNR')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c7e0ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (700, 512, 512, 3)\n",
      "Shape of test images: (15, 512, 512, 3)\n",
      "Shape of validation images: (140, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "train_high_image = high_img[:700]\n",
    "train_low_image = low_img[:700]\n",
    "train_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\n",
    "train_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n",
    "\n",
    "validation_high_image = high_img[700:840]\n",
    "validation_low_image = low_img[700:840]\n",
    "validation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\n",
    "validation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n",
    "\n",
    "\n",
    "test_high_image = high_img[840:]\n",
    "test_low_image = low_img[840:]\n",
    "test_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3)) #(number of obvs,size,size,Color dimention)\n",
    "test_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n",
    "\n",
    "print(\"Shape of training images:\",train_high_image.shape)\n",
    "print(\"Shape of test images:\",test_high_image.shape)\n",
    "print(\"Shape of validation images:\",validation_high_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bf9a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(high,low,predicted):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('High Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(high)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Low Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(low)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n",
    "    plt.imshow(predicted)\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03b51b",
   "metadata": {},
   "source": [
    "# Models - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844808b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test harness for evaluating models on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(512, 512, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2DTranspose(3, (2, 2),strides = 2))\n",
    "model.add(Conv2DTranspose(64, (2, 2),strides = 2))\n",
    "model.add(Conv2DTranspose(64, (2, 2),strides = 2))\n",
    "model.add(Conv2DTranspose(64, (2, 2),strides = 2))\n",
    "model.add(Conv2DTranspose(3, (2, 2),strides = 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8f82940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2130ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n",
    "              metrics = ['acc',PSNR, SSIM])\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "history = model.fit(train_low_image, train_high_image, epochs = 20, batch_size = 16,callbacks=[earlystop_callback],\n",
    "          validation_data = (validation_low_image,validation_high_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b0f10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test harness for evaluating models on the cifar10 dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(512, 512, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2DTranspose(3, (2, 2),strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2caa6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_56 (Conv2D)          (None, 512, 512, 32)      896       \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 512, 512, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 256, 256, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 256, 256, 16)      9232      \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 256, 256, 64)      9280      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 128, 128, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 128, 128, 32)      18464     \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 128, 128, 128)     36992     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 64, 64, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 64, 64, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 16, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose_27 (Conv2D  (None, 32, 32, 3)        1539      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_28 (Conv2D  (None, 64, 64, 64)       832       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_29 (Conv2D  (None, 128, 128, 64)     16448     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_30 (Conv2D  (None, 256, 256, 64)     16448     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_31 (Conv2D  (None, 512, 512, 3)      771       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 572,214\n",
      "Trainable params: 572,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b6577ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 21:37:12.590733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.1073 - acc: 0.5037 - PSNR: inf - SSIM: 0.5793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 21:37:41.602682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 32s 697ms/step - loss: 0.1073 - acc: 0.5037 - PSNR: inf - SSIM: 0.5793 - val_loss: 0.0347 - val_acc: 0.7262 - val_PSNR: 31.1508 - val_SSIM: 0.8056\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 29s 643ms/step - loss: 0.0257 - acc: 0.7835 - PSNR: 34.8105 - SSIM: 0.8860 - val_loss: 0.0242 - val_acc: 0.7770 - val_PSNR: 35.9754 - val_SSIM: 0.9007\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 29s 648ms/step - loss: 0.0225 - acc: 0.8094 - PSNR: 36.4884 - SSIM: 0.9118 - val_loss: 0.0222 - val_acc: 0.7819 - val_PSNR: 36.4617 - val_SSIM: 0.9119\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 29s 649ms/step - loss: 0.0215 - acc: 0.8133 - PSNR: 36.7638 - SSIM: 0.9170 - val_loss: 0.0218 - val_acc: 0.8193 - val_PSNR: 36.6707 - val_SSIM: 0.9103\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 29s 657ms/step - loss: 0.0197 - acc: 0.8293 - PSNR: 37.8033 - SSIM: 0.9277 - val_loss: 0.0195 - val_acc: 0.7991 - val_PSNR: 37.8661 - val_SSIM: 0.9299\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 30s 671ms/step - loss: 0.0185 - acc: 0.8281 - PSNR: 38.4000 - SSIM: 0.9349 - val_loss: 0.0184 - val_acc: 0.8091 - val_PSNR: 38.5847 - val_SSIM: 0.9341\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 29s 659ms/step - loss: 0.0177 - acc: 0.8335 - PSNR: 38.5085 - SSIM: 0.9373 - val_loss: 0.0175 - val_acc: 0.8268 - val_PSNR: 38.8165 - val_SSIM: 0.9364\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 29s 657ms/step - loss: 0.0170 - acc: 0.8422 - PSNR: 38.8945 - SSIM: 0.9430 - val_loss: 0.0162 - val_acc: 0.8574 - val_PSNR: 39.8913 - val_SSIM: 0.9426\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 29s 650ms/step - loss: 0.0164 - acc: 0.8385 - PSNR: 39.0802 - SSIM: 0.9431 - val_loss: 0.0170 - val_acc: 0.8281 - val_PSNR: 38.8352 - val_SSIM: 0.9446\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 29s 663ms/step - loss: 0.0161 - acc: 0.8445 - PSNR: 39.3295 - SSIM: 0.9457 - val_loss: 0.0170 - val_acc: 0.8000 - val_PSNR: 38.2684 - val_SSIM: 0.9438\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 30s 670ms/step - loss: 0.0153 - acc: 0.8530 - PSNR: 40.0778 - SSIM: 0.9484 - val_loss: 0.0158 - val_acc: 0.8408 - val_PSNR: 39.5589 - val_SSIM: 0.9450\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 29s 662ms/step - loss: 0.0158 - acc: 0.8429 - PSNR: 39.5635 - SSIM: 0.9472 - val_loss: 0.0167 - val_acc: 0.8330 - val_PSNR: 38.4522 - val_SSIM: 0.9423\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 29s 653ms/step - loss: 0.0156 - acc: 0.8427 - PSNR: 39.6286 - SSIM: 0.9482 - val_loss: 0.0152 - val_acc: 0.8320 - val_PSNR: 40.3506 - val_SSIM: 0.9478\n",
      "Epoch 14/20\n",
      "44/44 [==============================] - 29s 662ms/step - loss: 0.0150 - acc: 0.8481 - PSNR: 40.3305 - SSIM: 0.9493 - val_loss: 0.0156 - val_acc: 0.8090 - val_PSNR: 39.3972 - val_SSIM: 0.9448\n",
      "Epoch 15/20\n",
      "44/44 [==============================] - 29s 661ms/step - loss: 0.0160 - acc: 0.8325 - PSNR: 39.1117 - SSIM: 0.9454 - val_loss: 0.0152 - val_acc: 0.8262 - val_PSNR: 40.2764 - val_SSIM: 0.9480\n",
      "Epoch 16/20\n",
      "44/44 [==============================] - 29s 660ms/step - loss: 0.0156 - acc: 0.8371 - PSNR: 39.4924 - SSIM: 0.9467 - val_loss: 0.0154 - val_acc: 0.8548 - val_PSNR: 39.9402 - val_SSIM: 0.9492\n",
      "Epoch 17/20\n",
      "44/44 [==============================] - 29s 654ms/step - loss: 0.0157 - acc: 0.8540 - PSNR: 39.6079 - SSIM: 0.9509 - val_loss: 0.0152 - val_acc: 0.8680 - val_PSNR: 40.2410 - val_SSIM: 0.9501\n",
      "Epoch 18/20\n",
      "44/44 [==============================] - 29s 660ms/step - loss: 0.0145 - acc: 0.8586 - PSNR: 40.9407 - SSIM: 0.9525 - val_loss: 0.0146 - val_acc: 0.8915 - val_PSNR: 40.8720 - val_SSIM: 0.9508\n",
      "Epoch 19/20\n",
      "44/44 [==============================] - 29s 652ms/step - loss: 0.0149 - acc: 0.8539 - PSNR: 40.1996 - SSIM: 0.9514 - val_loss: 0.0148 - val_acc: 0.8366 - val_PSNR: 40.4599 - val_SSIM: 0.9488\n",
      "Epoch 20/20\n",
      "44/44 [==============================] - 29s 653ms/step - loss: 0.0147 - acc: 0.8522 - PSNR: 40.5588 - SSIM: 0.9521 - val_loss: 0.0148 - val_acc: 0.8531 - val_PSNR: 40.6126 - val_SSIM: 0.9496\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n",
    "              metrics = ['acc',PSNR, SSIM])\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "history = model.fit(train_low_image, train_high_image, epochs = 20, batch_size = 16,callbacks=[earlystop_callback],\n",
    "          validation_data = (validation_low_image,validation_high_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc4b3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"baseline-simple-val-best.h5\")\n",
    "import pickle \n",
    "\n",
    "with open('baseline-simple-val-best.pkl','wb') as handle:\n",
    "    pickle.dump(history.history,handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "558ccff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('baseline.pkl','rb') as handle:\n",
    "    history = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b724af6",
   "metadata": {},
   "source": [
    "# Models - Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b733d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 256, 256, 12  3584        ['input_2[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 128, 128, 12  147584      ['sequential_14[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)     (None, 64, 64, 256)  296192      ['sequential_15[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_17 (Sequential)     (None, 32, 32, 512)  1182208     ['sequential_16[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_18 (Sequential)     (None, 16, 16, 512)  2361856     ['sequential_17[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)     (None, 32, 32, 512)  2359808     ['sequential_18[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 32, 1024  0           ['sequential_19[0][0]',          \n",
      "                                )                                 'sequential_17[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_20 (Sequential)     (None, 64, 64, 256)  2359552     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 64, 64, 512)  0           ['sequential_20[0][0]',          \n",
      "                                                                  'sequential_16[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)     (None, 128, 128, 12  589952      ['concatenate_7[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 128, 128, 25  0           ['sequential_21[0][0]',          \n",
      "                                6)                                'sequential_15[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_22 (Sequential)     (None, 256, 256, 12  295040      ['concatenate_8[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 256, 256, 25  0           ['sequential_22[0][0]',          \n",
      "                                6)                                'sequential_14[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_23 (Sequential)     (None, 512, 512, 3)  6915        ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 512, 512, 6)  0           ['sequential_23[0][0]',          \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 512, 512, 3)  75          ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,602,766\n",
      "Trainable params: 9,600,206\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "def down_level(filters , kernel_size, apply_batch_normalization = False):\n",
    "    downsample = tf.keras.models.Sequential()\n",
    "    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n",
    "    if apply_batch_normalization:\n",
    "        downsample.add(layers.BatchNormalization())\n",
    "    downsample.add(keras.layers.LeakyReLU())\n",
    "    return downsample\n",
    "\n",
    "\n",
    "def up_level(filters, kernel_size, dropout = False):\n",
    "    upsample = tf.keras.models.Sequential()\n",
    "    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n",
    "    if dropout:\n",
    "        upsample.dropout(0.2)\n",
    "    upsample.add(keras.layers.LeakyReLU())\n",
    "    return upsample\n",
    "\n",
    "def model():\n",
    "    inputs = layers.Input(shape= [SIZE,SIZE,3])\n",
    "    l1 = down_level(128,(3,3),False)(inputs)\n",
    "    l2 = down_level(128,(3,3),False)(l1)\n",
    "    l3 = down_level(256,(3,3),True)(l2)\n",
    "    l4 = down_level(512,(3,3),True)(l3)\n",
    "    \n",
    "    l5 = down(512,(3,3),True)(l4)\n",
    "#     d6 = down(1024,(3,3),True)(d5)\n",
    "    #upsampling\n",
    "#     u0 = up(1024,(3,3),False)(d6)\n",
    "#     u0 = layers.concatenate([u0,d5])\n",
    "    h1 = up_level(512,(3,3),False)(l5)\n",
    "    h1 = layers.concatenate([h1,l4])\n",
    "    h2 = up_level(256,(3,3),False)(h1)\n",
    "    h2 = layers.concatenate([h2,l3])\n",
    "    h3 = up_level(128,(3,3),False)(h2)\n",
    "    h3 = layers.concatenate([h3,l2])\n",
    "    h4 = up_level(128,(3,3),False)(h3)\n",
    "    h4 = layers.concatenate([h4,l1])\n",
    "    h5 = up_level(3,(3,3),False)(u4)\n",
    "    h5 = layers.concatenate([h5,inputs])\n",
    "    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(uh5)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12877acc",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/nirawitkanthachai/low-resolution-images-to-high-resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54c1e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:19:19.156801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.6495 - PSNR: 31.3012 - SSIM: 0.8666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:20:42.959194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 93s 129ms/step - loss: 0.0386 - acc: 0.6495 - PSNR: 31.3012 - SSIM: 0.8666 - val_loss: 0.0256 - val_acc: 0.7292 - val_PSNR: 34.0718 - val_SSIM: 0.9258\n",
      "Epoch 2/20\n",
      "700/700 [==============================] - 89s 127ms/step - loss: 0.0217 - acc: 0.7853 - PSNR: 35.7429 - SSIM: 0.9303 - val_loss: 0.0196 - val_acc: 0.8110 - val_PSNR: 35.5403 - val_SSIM: 0.9461\n",
      "Epoch 3/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0184 - acc: 0.7992 - PSNR: 37.0852 - SSIM: 0.9501 - val_loss: 0.0164 - val_acc: 0.8438 - val_PSNR: 37.7973 - val_SSIM: 0.9527\n",
      "Epoch 4/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0155 - acc: 0.8278 - PSNR: 38.7620 - SSIM: 0.9578 - val_loss: 0.0148 - val_acc: 0.8316 - val_PSNR: 39.4523 - val_SSIM: 0.9581\n",
      "Epoch 5/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0149 - acc: 0.8297 - PSNR: 39.2518 - SSIM: 0.9598 - val_loss: 0.0145 - val_acc: 0.8944 - val_PSNR: 39.1065 - val_SSIM: 0.9594\n",
      "Epoch 6/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0144 - acc: 0.8388 - PSNR: 39.4673 - SSIM: 0.9627 - val_loss: 0.0141 - val_acc: 0.8112 - val_PSNR: 39.7997 - val_SSIM: 0.9633\n",
      "Epoch 7/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0135 - acc: 0.8470 - PSNR: 40.3390 - SSIM: 0.9643 - val_loss: 0.0128 - val_acc: 0.9144 - val_PSNR: 40.8370 - val_SSIM: 0.9648\n",
      "Epoch 8/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0133 - acc: 0.8544 - PSNR: 40.3084 - SSIM: 0.9645 - val_loss: 0.0114 - val_acc: 0.8665 - val_PSNR: 42.9278 - val_SSIM: 0.9670\n",
      "Epoch 9/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0135 - acc: 0.8523 - PSNR: 40.2768 - SSIM: 0.9651 - val_loss: 0.0124 - val_acc: 0.8374 - val_PSNR: 41.5053 - val_SSIM: 0.9652\n",
      "Epoch 10/20\n",
      "700/700 [==============================] - 89s 127ms/step - loss: 0.0127 - acc: 0.8562 - PSNR: 40.9961 - SSIM: 0.9669 - val_loss: 0.0116 - val_acc: 0.8801 - val_PSNR: 42.9416 - val_SSIM: 0.9665\n",
      "Epoch 11/20\n",
      "700/700 [==============================] - 89s 127ms/step - loss: 0.0122 - acc: 0.8592 - PSNR: 41.5253 - SSIM: 0.9678 - val_loss: 0.0119 - val_acc: 0.8745 - val_PSNR: 42.3522 - val_SSIM: 0.9655\n",
      "Epoch 12/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0121 - acc: 0.8618 - PSNR: 41.4386 - SSIM: 0.9687 - val_loss: 0.0118 - val_acc: 0.8624 - val_PSNR: 42.3598 - val_SSIM: 0.9662\n",
      "Epoch 13/20\n",
      "700/700 [==============================] - 89s 127ms/step - loss: 0.0120 - acc: 0.8582 - PSNR: 41.4221 - SSIM: 0.9692 - val_loss: 0.0113 - val_acc: 0.8579 - val_PSNR: 43.0258 - val_SSIM: 0.9680\n",
      "Epoch 14/20\n",
      "700/700 [==============================] - 89s 126ms/step - loss: 0.0115 - acc: 0.8707 - PSNR: 42.2178 - SSIM: 0.9700 - val_loss: 0.0127 - val_acc: 0.8598 - val_PSNR: 41.0737 - val_SSIM: 0.9647\n",
      "Epoch 15/20\n",
      "700/700 [==============================] - 89s 126ms/step - loss: 0.0113 - acc: 0.8694 - PSNR: 42.1657 - SSIM: 0.9712 - val_loss: 0.0109 - val_acc: 0.8655 - val_PSNR: 43.8217 - val_SSIM: 0.9684\n",
      "Epoch 16/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0112 - acc: 0.8605 - PSNR: 42.1864 - SSIM: 0.9718 - val_loss: 0.0118 - val_acc: 0.8629 - val_PSNR: 41.8895 - val_SSIM: 0.9660\n",
      "Epoch 17/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0108 - acc: 0.8649 - PSNR: 42.3853 - SSIM: 0.9727 - val_loss: 0.0113 - val_acc: 0.9115 - val_PSNR: 43.0962 - val_SSIM: 0.9671\n",
      "Epoch 18/20\n",
      "700/700 [==============================] - 89s 126ms/step - loss: 0.0106 - acc: 0.8720 - PSNR: 42.6720 - SSIM: 0.9740 - val_loss: 0.0128 - val_acc: 0.8277 - val_PSNR: 40.3471 - val_SSIM: 0.9675\n",
      "Epoch 19/20\n",
      "700/700 [==============================] - 89s 126ms/step - loss: 0.0103 - acc: 0.8695 - PSNR: 43.0076 - SSIM: 0.9748 - val_loss: 0.0119 - val_acc: 0.8821 - val_PSNR: 42.4247 - val_SSIM: 0.9668\n",
      "Epoch 20/20\n",
      "700/700 [==============================] - 88s 126ms/step - loss: 0.0103 - acc: 0.8768 - PSNR: 42.8156 - SSIM: 0.9754 - val_loss: 0.0109 - val_acc: 0.8611 - val_PSNR: 44.1397 - val_SSIM: 0.9679\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n",
    "              metrics = ['acc',PSNR, SSIM])\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "history = model.fit(train_low_image, train_high_image, epochs = 20, batch_size = 1,callbacks=[earlystop_callback],\n",
    "          validation_data = (validation_low_image,validation_high_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8507cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(history.epoch, history.history[\"PSNR\"], 'g', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0412367",
   "metadata": {},
   "source": [
    "## Testing on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'test6.jpg',1)\n",
    "\n",
    " #resizing image\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (SIZE, SIZE))\n",
    "img = img.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "predicted = np.clip(model.predict(img.reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
    "predicted = cv2.cvtColor(predicted, cv2.COLOR_BGR2RGB)\n",
    "plot_images(img,img,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47222fff",
   "metadata": {},
   "source": [
    "## Pickling model and saving history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d57ffaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model_psnr_512-val.h5\")\n",
    "import pickle \n",
    "\n",
    "with open('final_model_concate_512-val.pkl','wb') as handle:\n",
    "    pickle.dump(history.history,handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5a731",
   "metadata": {},
   "source": [
    "# Models - Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a780e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "def encoder(input, num_filters):\n",
    "    x = conv(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "def decoder(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv(x, num_filters)\n",
    "    return x\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    s1, p1 = encoder(inputs, 64)\n",
    "    s2, p2 = encoder(p1, 128)\n",
    "    s3, p3 = encoder(p2, 256)\n",
    "    s4, p4 = encoder(p3, 512)\n",
    "    b1 = conv(p4, 1024)\n",
    "    d1 = decoder(b1, s4, 512)\n",
    "    d2 = decoder(d1, s3, 256)\n",
    "    d3 = decoder(d2, s2, 128)\n",
    "    d4 = decoder(d3, s1, 64)\n",
    "\n",
    "\n",
    "    outputs = Conv2D(3, 3, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14ef94",
   "metadata": {},
   "source": [
    "https://idiotdeveloper.com/unet-implementation-in-tensorflow-using-keras-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d35438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet((512, 512, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64dc11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 512, 512, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 512, 512, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 512, 512, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 256, 256, 12  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 256, 256, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_4[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_5[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['activation_9[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_11[0][0]']          \n",
      " spose)                         6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                2)                                'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 128, 128, 25  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_12[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 128, 25  590080      ['activation_12[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 128, 128, 25  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_13[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_13[0][0]']          \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                6)                                'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 256, 256, 12  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 256, 256, 12  147584      ['activation_14[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 256, 256, 12  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                  8)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_15[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 512, 512, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 512, 512, 64  36928       ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 512, 512, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 512, 512, 3)  1731        ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,056,963\n",
      "Trainable params: 31,045,187\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c09dabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:49:58.058119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 0.0718 - acc: 0.6217 - PSNR: 24.4548 - SSIM: 0.8299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 17:55:15.992176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 338s 4s/step - loss: 0.0718 - acc: 0.6217 - PSNR: 24.4548 - SSIM: 0.8299 - val_loss: 0.3873 - val_acc: 0.2943 - val_PSNR: 8.5912 - val_SSIM: 0.1916\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 337s 4s/step - loss: 0.0617 - acc: 0.6849 - PSNR: 25.7077 - SSIM: 0.8745 - val_loss: 0.1877 - val_acc: 0.4687 - val_PSNR: 15.6282 - val_SSIM: 0.6727\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 327s 4s/step - loss: 0.0606 - acc: 0.6869 - PSNR: 25.8678 - SSIM: 0.8840 - val_loss: 0.1484 - val_acc: 0.6314 - val_PSNR: 17.8022 - val_SSIM: 0.7336\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 329s 4s/step - loss: 0.0532 - acc: 0.6877 - PSNR: 26.8409 - SSIM: 0.8986 - val_loss: 0.1005 - val_acc: 0.6415 - val_PSNR: 21.5726 - val_SSIM: 0.7844\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 336s 4s/step - loss: 0.0553 - acc: 0.6999 - PSNR: 26.7540 - SSIM: 0.8982 - val_loss: 0.0873 - val_acc: 0.6644 - val_PSNR: 23.3583 - val_SSIM: 0.7822\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 333s 4s/step - loss: 0.0535 - acc: 0.6836 - PSNR: inf - SSIM: 0.9029 - val_loss: 0.0794 - val_acc: 0.6883 - val_PSNR: inf - val_SSIM: 0.8857\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 329s 4s/step - loss: 0.0533 - acc: 0.6914 - PSNR: inf - SSIM: 0.9043 - val_loss: 0.0487 - val_acc: 0.6831 - val_PSNR: inf - val_SSIM: 0.8933\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 327s 4s/step - loss: 0.0489 - acc: 0.7085 - PSNR: inf - SSIM: 0.9063 - val_loss: 0.1907 - val_acc: 0.6226 - val_PSNR: inf - val_SSIM: 0.7581\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 325s 4s/step - loss: 0.0497 - acc: 0.7061 - PSNR: inf - SSIM: 0.9066 - val_loss: 0.0431 - val_acc: 0.7755 - val_PSNR: inf - val_SSIM: 0.9250\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 325s 4s/step - loss: 0.0480 - acc: 0.7063 - PSNR: inf - SSIM: 0.9050 - val_loss: 0.0683 - val_acc: 0.6418 - val_PSNR: inf - val_SSIM: 0.8534\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 329s 4s/step - loss: 0.0423 - acc: 0.7324 - PSNR: inf - SSIM: 0.9125 - val_loss: 0.3336 - val_acc: 0.6265 - val_PSNR: inf - val_SSIM: 0.6207\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 326s 4s/step - loss: 0.0412 - acc: 0.7272 - PSNR: inf - SSIM: 0.9133 - val_loss: 0.0425 - val_acc: 0.7156 - val_PSNR: 29.0950 - val_SSIM: 0.9189\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 326s 4s/step - loss: 0.0396 - acc: 0.7342 - PSNR: inf - SSIM: 0.9187 - val_loss: 0.0364 - val_acc: 0.7618 - val_PSNR: 29.5799 - val_SSIM: 0.9315\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 325s 4s/step - loss: 0.0399 - acc: 0.7253 - PSNR: inf - SSIM: 0.9140 - val_loss: 0.0338 - val_acc: 0.7236 - val_PSNR: inf - val_SSIM: 0.9224\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 325s 4s/step - loss: 0.0408 - acc: 0.7132 - PSNR: inf - SSIM: 0.9170 - val_loss: 0.0431 - val_acc: 0.7046 - val_PSNR: inf - val_SSIM: 0.9001\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 324s 4s/step - loss: 0.0403 - acc: 0.7284 - PSNR: inf - SSIM: 0.9143 - val_loss: 0.0319 - val_acc: 0.7980 - val_PSNR: 32.0435 - val_SSIM: 0.9075\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 326s 4s/step - loss: 0.0393 - acc: 0.7208 - PSNR: inf - SSIM: 0.9169 - val_loss: 0.0341 - val_acc: 0.7551 - val_PSNR: 31.0621 - val_SSIM: 0.9289\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 327s 4s/step - loss: 0.0354 - acc: 0.7392 - PSNR: inf - SSIM: 0.9210 - val_loss: 0.0424 - val_acc: 0.8113 - val_PSNR: inf - val_SSIM: 0.9165\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 329s 4s/step - loss: 0.0356 - acc: 0.7405 - PSNR: inf - SSIM: 0.9221 - val_loss: 0.0239 - val_acc: 0.7625 - val_PSNR: inf - val_SSIM: 0.9314\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 325s 4s/step - loss: 0.0373 - acc: 0.7333 - PSNR: inf - SSIM: 0.9230 - val_loss: 0.0378 - val_acc: 0.6878 - val_PSNR: 29.7125 - val_SSIM: 0.9282\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n",
    "              metrics = ['acc',PSNR, SSIM])\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "history = model.fit(train_low_image, train_high_image, epochs = 20, batch_size = 8,callbacks=[earlystop_callback],\n",
    "          validation_data = (validation_low_image,validation_high_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    \n",
    "    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
    "    test_low_image[i] = cv2.cvtColor(test_low_image[i], cv2.COLOR_BGR2RGB)\n",
    "    plot_images(test_high_image[i],test_low_image[i],predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83db91",
   "metadata": {},
   "source": [
    "## Testing on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e221257",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('woman.png',1)\n",
    "#img = img[:96,:96,:]\n",
    "print(img.shape)\n",
    "\n",
    "        #resizing image\n",
    "img = cv2.resize(img, (SIZE, SIZE))\n",
    "img = img.astype('float32') / 255.0\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "predicted = np.clip(model.predict(img.reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
    "predicted = cv2.cvtColor(predicted, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plot_images(img,img,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba674872",
   "metadata": {},
   "source": [
    "## Pickling the model and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd38c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet-val.h5\")\n",
    "import pickle \n",
    "\n",
    "with open('unet-val.pkl','wb') as handle:\n",
    "    pickle.dump(history.history,handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
